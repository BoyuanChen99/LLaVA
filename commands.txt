
### Inference: 
python -m llava.serve.cli \
    --model-path liuhaotian/llava-v1.5-7b \
    --image-file "https://llava-vl.github.io/static/images/view.jpg" \
    --load-4bit

### Dataset Answer Generation: 
# Follow the instructions in the official webpage: https://github.com/haotian-liu/LLaVA/blob/main/docs/Evaluation.md
python model_vqa.py \
    --model-path "/home/bc3194/Desktop/huggingface_cache" \
    --question-file \
    playground/data/coco2014_val_qa_eval/qa90_questions.jsonl \
    --image-folder \
    /path/to/coco2014_val \
    --answers-file \
    /path/to/answer-file-our.jsonl